{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from os.path import join\n",
    "\n",
    "from script.core.transformers import *\n",
    "from script.models.cnn import CNN\n",
    "from script.core.models import *\n",
    "from script.core.dataset import Watcher\n",
    "from script.core.utils import read_dataset, get_result, logging\n",
    "from script.core.pipeline import Pipeline\n",
    "\n",
    "# linear models\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# sklearn feachure extractors\n",
    "from sklearn.feature_extraction.text import CountVectorizer as count\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tfidf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Pure DilyaraModel\n",
    "# from intent_classifier.intent_model.model_wrap import KerasMulticlassModel as DilyaraModel\n",
    "# from script.models.cnn import CNN\n",
    "# from script.models.dcnn import DCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read csv file and create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mks/envs/intent_script/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2910: DtypeWarning: Columns (6,7,10,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "def init_dataset_tiny(file_path, language, dataset_name, date, seed=42):\n",
    "    pure_data = read_dataset(file_path, True, True)  # It not default meanings!!!\n",
    "    start_dataset = Watcher(pure_data, date, language, dataset_name,\n",
    "                            seed=seed)  # classes_descriptions = {} we can do it\n",
    "\n",
    "    ######################################################################################\n",
    "    dataset = start_dataset.split([0.1, 0.1])\n",
    "    data = dataset.data['test']\n",
    "    start_dataset = Watcher(data, date, language, dataset_name, seed)\n",
    "    ######################################################################################\n",
    "\n",
    "    return start_dataset\n",
    "\n",
    "date = datetime.datetime.now()\n",
    "dataset_name = 'vkusvill'\n",
    "language = 'russian'\n",
    "file_path = join('./data', language, dataset_name, 'data', 'vkusvill_all_categories.csv')\n",
    "\n",
    "dataset = init_dataset_tiny(file_path, language, dataset_name, date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spl_conf = {'op_type': 'transformer',\n",
    "            'name': 'Speller',\n",
    "            'request_names': ['base'],\n",
    "            'new_names': ['base'],\n",
    "            'path': './DeepPavlov/deeppavlov/configs/error_model/brillmoore_kartaslov_ru.json'}\n",
    "\n",
    "tok_conf = {'op_type': 'transformer',\n",
    "            'name': 'Tokenizer',\n",
    "            'request_names': ['base'],\n",
    "            'new_names': ['base']}\n",
    "\n",
    "lem_conf = {'op_type': 'transformer',\n",
    "            'name': 'Lemmatizer',\n",
    "            'request_names': ['base'],\n",
    "            'new_names': ['base']}\n",
    "\n",
    "concat = TextConcat()\n",
    "\n",
    "tfidf_conf_1 = {'op_type': 'vectorizer', 'name': 'tf-idf vectorizer',\n",
    "                'request_names': ['train', 'valid', 'test'], 'new_names': ['train_vec', 'valid_vec', 'test_vec']}\n",
    "tfidf_conf_2 = {'op_type': 'vectorizer', 'name': 'count_vectorizer',\n",
    "                'request_names': ['train', 'valid', 'test'], 'new_names': ['train_vec', 'valid_vec', 'test_vec']}\n",
    "tfidf_ = sktransformer(tfidf, tfidf_conf_1)\n",
    "count_ = sktransformer(count, tfidf_conf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'в магазине 634м дм донского2 место выкладки теплые стеллажи нонфуд зафиксирована температура ниже 18 температура на начало дня 16 температура на конец дня 17'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data['base']['request'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_cnn_conf(path_1, emb_path)\n",
    "WCNN = GetCNN(CNN, config)\n",
    "pipe = Pipeline([(Tokenizer,), (FasttextVectorizer,), (WCNN,)])\n",
    "pipe.run(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.load_data('427e247b44e0ec75a3d1660a500c198d')\n",
    "dataset.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report</th>\n",
       "      <th>request</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>в магазине 634м дм донского2 место выкладки те...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>здравствуйте купили сегодня огурцы среднеплодн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>дата пр ва 17 03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>ассортимент</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>проверить налие купона</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>рыкун галина александровна очень не вежлива не...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>творог мягкий диетечиский 4 5 кислый есть нево...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>неудобный магазин на вешняковской недавно вмес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>снеки фруктово ягодные черничные внутри стекло...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>биффилайф детский черника 2 5 хотим видеть в н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6</td>\n",
       "      <td>был здесь в группе как то опрос общественного ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>правда меня озадачила надпись пищевая добавка ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>и опять про бабу муж только принес от 20 числа...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>от 07 09 плесень на сыре</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>шариков не попадалось всё вроде по честному но...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>приобрели арбуз разрезали а он внутри наполови...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>выраженный запах нечистот вкус такой же дата п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>лк</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>13</td>\n",
       "      <td>отравление кефиром добрый день 22 06 2016 в ма...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>22 08 2017 14 59 02 муж купил вчера розовые по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>добрый день купила новинку рыбу дорадо вчера 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10</td>\n",
       "      <td>списание по качеству партия от 30 12 2016 вклю...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>крайней неприятный кассир послала нам множеств...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>очень вкусный торт морковный прям для меня все...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9</td>\n",
       "      <td>дорогой вкусвилл бесконечно благодарна вам за ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>в магазине 1010м сущевская9 место выкладки теп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>сотрудник кассы вел себя грубо швырнул карту н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>в магазине 1206м хабаровская8 место выкладки т...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>в магазине 971м шоссейная1 место выкладки тепл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>списание по качеству партия от 25 10 2016 вклю...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4445</th>\n",
       "      <td>2</td>\n",
       "      <td>лп</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4446</th>\n",
       "      <td>7</td>\n",
       "      <td>а еще из недавно распробованного спасибо зел ц...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4447</th>\n",
       "      <td>2</td>\n",
       "      <td>плохой плохой салат салат мимоза д в 15 05 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4448</th>\n",
       "      <td>6</td>\n",
       "      <td>вкусвилл добрый вечер часто покупаем сметану о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>6</td>\n",
       "      <td>добрый день купил детский кефир 7 шт из них 2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4450</th>\n",
       "      <td>7</td>\n",
       "      <td>приобрели вчера по зц скумбрия с с ломтики пря...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>15</td>\n",
       "      <td>в магазине 1225м долг лихачевское11 место выкл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452</th>\n",
       "      <td>1</td>\n",
       "      <td>верните в магазин мясо рапаны черноморской с м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>1</td>\n",
       "      <td>просьба завезти овсянку геркулес в вв на янгел...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4454</th>\n",
       "      <td>3</td>\n",
       "      <td>борш украинский очень ждем в вашем магазине</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4455</th>\n",
       "      <td>1</td>\n",
       "      <td>в магазине 1226м шарикоподшипниковская36 место...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>3</td>\n",
       "      <td>дата производства от 19 10 человек очень сильн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4457</th>\n",
       "      <td>6</td>\n",
       "      <td>добрый день мусс кефирно ежевичный очень вкусн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4458</th>\n",
       "      <td>12</td>\n",
       "      <td>дорогой вкусвилл вопрос к вам возможно уже пов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>14</td>\n",
       "      <td>довольно сладкий хотелось бы что то нейтрально...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4460</th>\n",
       "      <td>2</td>\n",
       "      <td>приобрела масло сливочное 82 5 жуковское молок...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>16</td>\n",
       "      <td>вв ну что это такое чем дальше тем вкуснее пос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>6</td>\n",
       "      <td>покупаю у вас продукты уже какое то время всем...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>3</td>\n",
       "      <td>елена шевченко здравствуйте скажите пожалуйста...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>6</td>\n",
       "      <td>12 12 отправила дочь в магазин пробили лишний ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4465</th>\n",
       "      <td>10</td>\n",
       "      <td>сегодня купила скумбрию и у меня на нее начала...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>13</td>\n",
       "      <td>видел в конце прошлой недели пряник в форме ко...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4467</th>\n",
       "      <td>7</td>\n",
       "      <td>я буду сейчас дико ругаться ну эт невозможно д...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4468</th>\n",
       "      <td>7</td>\n",
       "      <td>milla li по своему опыту скажу котлеты от дант...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4469</th>\n",
       "      <td>7</td>\n",
       "      <td>разочарования пост увидела новинку шашлычок из...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4470</th>\n",
       "      <td>3</td>\n",
       "      <td>в магазине 985м реут комсомольская18 место вык...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471</th>\n",
       "      <td>6</td>\n",
       "      <td>жк 22 09 купила в этом магазине готовую еду гр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4472</th>\n",
       "      <td>12</td>\n",
       "      <td>партия от 23 08 2016 очень сухая и жесткая рыб...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4473</th>\n",
       "      <td>6</td>\n",
       "      <td>в магазине уже не в первый раз продавец хохлов...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4474</th>\n",
       "      <td>7</td>\n",
       "      <td>на кого зарегестрирована карта</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4475 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      report                                            request\n",
       "0         13  в магазине 634м дм донского2 место выкладки те...\n",
       "1          3  здравствуйте купили сегодня огурцы среднеплодн...\n",
       "2          1                                   дата пр ва 17 03\n",
       "3          7                                        ассортимент\n",
       "4          6                             проверить налие купона\n",
       "5          6  рыкун галина александровна очень не вежлива не...\n",
       "6          1  творог мягкий диетечиский 4 5 кислый есть нево...\n",
       "7          1  неудобный магазин на вешняковской недавно вмес...\n",
       "8          6  снеки фруктово ягодные черничные внутри стекло...\n",
       "9          3  биффилайф детский черника 2 5 хотим видеть в н...\n",
       "10         6  был здесь в группе как то опрос общественного ...\n",
       "11        13  правда меня озадачила надпись пищевая добавка ...\n",
       "12         6  и опять про бабу муж только принес от 20 числа...\n",
       "13         2                           от 07 09 плесень на сыре\n",
       "14         3  шариков не попадалось всё вроде по честному но...\n",
       "15         6  приобрели арбуз разрезали а он внутри наполови...\n",
       "16         1  выраженный запах нечистот вкус такой же дата п...\n",
       "17         1                                                 лк\n",
       "18        13  отравление кефиром добрый день 22 06 2016 в ма...\n",
       "19         6  22 08 2017 14 59 02 муж купил вчера розовые по...\n",
       "20         6  добрый день купила новинку рыбу дорадо вчера 0...\n",
       "21        10  списание по качеству партия от 30 12 2016 вклю...\n",
       "22         6  крайней неприятный кассир послала нам множеств...\n",
       "23         6  очень вкусный торт морковный прям для меня все...\n",
       "24         9  дорогой вкусвилл бесконечно благодарна вам за ...\n",
       "25        12  в магазине 1010м сущевская9 место выкладки теп...\n",
       "26         1  сотрудник кассы вел себя грубо швырнул карту н...\n",
       "27         3  в магазине 1206м хабаровская8 место выкладки т...\n",
       "28         3  в магазине 971м шоссейная1 место выкладки тепл...\n",
       "29         6  списание по качеству партия от 25 10 2016 вклю...\n",
       "...      ...                                                ...\n",
       "4445       2                                                 лп\n",
       "4446       7  а еще из недавно распробованного спасибо зел ц...\n",
       "4447       2  плохой плохой салат салат мимоза д в 15 05 201...\n",
       "4448       6  вкусвилл добрый вечер часто покупаем сметану о...\n",
       "4449       6  добрый день купил детский кефир 7 шт из них 2 ...\n",
       "4450       7  приобрели вчера по зц скумбрия с с ломтики пря...\n",
       "4451      15  в магазине 1225м долг лихачевское11 место выкл...\n",
       "4452       1  верните в магазин мясо рапаны черноморской с м...\n",
       "4453       1  просьба завезти овсянку геркулес в вв на янгел...\n",
       "4454       3        борш украинский очень ждем в вашем магазине\n",
       "4455       1  в магазине 1226м шарикоподшипниковская36 место...\n",
       "4456       3  дата производства от 19 10 человек очень сильн...\n",
       "4457       6  добрый день мусс кефирно ежевичный очень вкусн...\n",
       "4458      12  дорогой вкусвилл вопрос к вам возможно уже пов...\n",
       "4459      14  довольно сладкий хотелось бы что то нейтрально...\n",
       "4460       2  приобрела масло сливочное 82 5 жуковское молок...\n",
       "4461      16  вв ну что это такое чем дальше тем вкуснее пос...\n",
       "4462       6  покупаю у вас продукты уже какое то время всем...\n",
       "4463       3  елена шевченко здравствуйте скажите пожалуйста...\n",
       "4464       6  12 12 отправила дочь в магазин пробили лишний ...\n",
       "4465      10  сегодня купила скумбрию и у меня на нее начала...\n",
       "4466      13  видел в конце прошлой недели пряник в форме ко...\n",
       "4467       7  я буду сейчас дико ругаться ну эт невозможно д...\n",
       "4468       7  milla li по своему опыту скажу котлеты от дант...\n",
       "4469       7  разочарования пост увидела новинку шашлычок из...\n",
       "4470       3  в магазине 985м реут комсомольская18 место вык...\n",
       "4471       6  жк 22 09 купила в этом магазине готовую еду гр...\n",
       "4472      12  партия от 23 08 2016 очень сухая и жесткая рыб...\n",
       "4473       6  в магазине уже не в первый раз продавец хохлов...\n",
       "4474       7                     на кого зарегестрирована карта\n",
       "\n",
       "[4475 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data['base']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = dataset.data['base']['request'][0]\n",
    "# s = s[1:-1]\n",
    "# s = s.split(', ')\n",
    "# s = [x[1:-1] for x in s]\n",
    "# s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = lambda s: [x[1:-1] for x in s[1:-1].split(', ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data['base']['request'] = dataset.data['base']['request'].apply(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data['base']['request'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_cnn_conf(path_1, emb_path)\n",
    "WCNN = GetCNN(CNN, config)\n",
    "pipe = Pipeline([(FasttextVectorizer,), (WCNN,)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 181/3661 [00:00<00:01, 1802.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Starting vectorization ... ]\n",
      "[ Vectorization of train part of dataset ... ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3661/3661 [00:01<00:00, 1971.09it/s]\n",
      " 43%|████▎     | 177/407 [00:00<00:00, 1765.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Vectorization of valid part of dataset ... ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [00:00<00:00, 1867.32it/s]\n",
      " 43%|████▎     | 173/407 [00:00<00:00, 1723.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Vectorization of test part of dataset ... ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 407/407 [00:00<00:00, 1758.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ Vectorization was ended. ]\n",
      "[ Initializing intent_model from scratch ]\n",
      "\n",
      "____Training over 3661 samples____\n",
      "\n",
      "\n",
      "train -->\tupdates: 1\tloss: 0.358571857213974\tfmeasure: 0.0\t \n",
      "epochs_done: 1\n",
      "train -->\tupdates: 59\tloss: 0.23870240151882172\tfmeasure: 0.42696624994277954\t \n",
      "epochs_done: 2\n",
      "train -->\tupdates: 117\tloss: 0.19705097377300262\tfmeasure: 0.5416666269302368\t \n",
      "epochs_done: 3\n",
      "train -->\tupdates: 175\tloss: 0.18926946818828583\tfmeasure: 0.54347825050354\t \n",
      "epochs_done: 4\n",
      "train -->\tupdates: 233\tloss: 0.17898912727832794\tfmeasure: 0.5154638886451721\t \n",
      "epochs_done: 5\n"
     ]
    }
   ],
   "source": [
    "pipe.run(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with Neural Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetCNN(BaseModel):\n",
    "    def init_model(self, dataset):\n",
    "        classes = dataset.get_classes()\n",
    "        classes = ' '.join([str(x) for x in classes])\n",
    "        self.config['classes'] = classes\n",
    "        \n",
    "        super().init_model(dataset)\n",
    "        \n",
    "        return self\n",
    "\n",
    "def get_cnn_conf(path, emb_path, fit_names=None, predict_names=None, new_names=None):\n",
    "    with open(path, 'r') as conf:\n",
    "        config = json.load(conf)\n",
    "\n",
    "    config['op_type'] = 'model'\n",
    "    config['name'] = 'cnn'\n",
    "    \n",
    "    if fit_names is not None:\n",
    "        config['fit_names'] = fit_names\n",
    "    else:\n",
    "        config['fit_names'] = ['train_vec']\n",
    "    \n",
    "    if predict_names is not None:\n",
    "        config['predict_names'] = predict_names\n",
    "    else:\n",
    "        config['predict_names'] = ['test_vec']\n",
    "        \n",
    "    if new_names is not None:\n",
    "        config['new_names'] = new_names\n",
    "    else:\n",
    "        config['new_names'] = ['predicted_test']\n",
    "    \n",
    "    config['fasttext_model'] = emb_path\n",
    "    \n",
    "    return config\n",
    "\n",
    "path_0 = './configs/models/CNN/CNN_opt.json'\n",
    "path_1 = './configs/models/CNN.json'\n",
    "emb_path = './data/russian/embeddings/ft_0.8.3_nltk_yalen_sg_300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = get_cnn_conf(path_0, emb_path, fit_names=['train'], predict_names=['test'])\n",
    "# dataset = init_dataset()\n",
    "# Dilyara = GetCNN(DilyaraModel, config)\n",
    "# neuro_pipe = [(Tokenizer, ), (Lemmatizer,), (TextConcat,), (Dilyara,), (GetResult,)]\n",
    "# pipeline_0 = Pipeline(neuro_pipe, mode='infer', output='dataset')\n",
    "# neurodata = pipeline_0.run(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_cnn_conf(path_1, emb_path)\n",
    "WCNN = GetCNN(CNN, config)\n",
    "neuro_pipe = [(Tokenizer, ), (FasttextVectorizer,), (WCNN,)]\n",
    "pipeline_1 = Pipeline(neuro_pipe, mode='train', output=None)\n",
    "neurodata = pipeline_1.run(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline_1.get_last_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe_ = [(Tokenizer, ), (FasttextVectorizer,)]\n",
    "# pipe = Pipeline(pipe_)\n",
    "\n",
    "# dataset = init_dataset_tiny(file_path, language, dataset_name, date)\n",
    "data = model.predict(dataset, predict_name='test_vec', new_name='pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.data['pred'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.data['predicted_test'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.data['predicted_test'][0][0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax = np.argmax(pred_data.data['predicted_test'][0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(pred_data.data['test']['report'][:64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetResult(BaseTransformer):\n",
    "    def __init__(self, config=None):\n",
    "        if config is None:\n",
    "            self.config = {'op_type': 'transformer',\n",
    "                           'name': 'Resulter',\n",
    "                           'request_names': ['predicted_test'],\n",
    "                           'new_names': ['test']}\n",
    "        else:\n",
    "            self.config = config\n",
    "\n",
    "        super().__init__(self.config)\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        request, report = dataset.main_names\n",
    "\n",
    "        pred_name = self.config['request_names'][0]\n",
    "        print(pred_name)\n",
    "        real_name = self.config['new_names'][0]\n",
    "        print(real_name)\n",
    "        pred_data = dataset.data[pred_name]\n",
    "        real_data = np.array(dataset.data[real_name][report])\n",
    "\n",
    "        preds = pred_data[0]\n",
    "        for x in pred_data[1:]:\n",
    "            preds = np.concatenate((preds, x), axis=0)\n",
    "\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        for i, x in enumerate(preds):\n",
    "            preds[i] = x + 1\n",
    "\n",
    "        preds = preds[:len(real_data)]\n",
    "\n",
    "        results = get_result(preds, real_data)\n",
    "        dataset.data['results'] = results\n",
    "\n",
    "        conf = dataset.pipeline_config\n",
    "        date = dataset.date\n",
    "        logging(results, conf, date)\n",
    "\n",
    "        return dataset\n",
    "\n",
    "end_pipe = Pipeline([(GetResult,)])\n",
    "end_res = end_pipe.run(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_res.data['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = get_cnn_conf(path_1, emb_path)\n",
    "# dataset = init_dataset()\n",
    "# WCNN = GetCNN(CNN, config)\n",
    "# neuro_pipe = [(Tokenizer, ), (FasttextVectorizer,), (WCNN,), (GetResult,)]\n",
    "# pipeline_1 = Pipeline(neuro_pipe, mode='infer', output='dataset')\n",
    "# neurodata = pipeline_1.run(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = get_cnn_conf(path_1, emb_path)\n",
    "# dataset = init_dataset()\n",
    "# dCNN = GetCNN(DCNN, config)\n",
    "# neuro_pipe = [(Tokenizer, ), (FasttextVectorizer,), (dCNN,), (GetResult,)]\n",
    "# pipeline_2 = Pipeline(neuro_pipe, mode='infer', output='dataset')\n",
    "# neurodata = pipeline_2.run(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines with Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_0 = {'op_type': 'model', 'name': 'Linear Regression',\n",
    "          'fit_names': ['train_vec'], 'new_names': ['predicted_test'],\n",
    "          'predict_names': ['test_vec']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline with linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Tokenizer, tok_conf), (Lemmatizer,), (concat, None),\n",
    "# dataset = init_dataset()\n",
    "# LR = skmodel(LogisticRegression, conf_0)\n",
    "\n",
    "# pipe_0 = [(tfidf_, tfidf_conf_2), (LR,), (GetResultLinear_W,)]\n",
    "# pipeline_0 = Pipeline(pipe_0, mode='train', output=None)\n",
    "# pipeline_1 = Pipeline(pipe_0, mode='infer', output='dataset')\n",
    "# res = pipeline_1.run(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline with SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = init_dataset()\n",
    "\n",
    "# conf_0['name'] = 'LinearSVC'\n",
    "# conf_0['op_type'] = 'model'\n",
    "# LSVC = skmodel(LinearSVC, conf_0)\n",
    "\n",
    "# # (Speller, spl_conf),\n",
    "\n",
    "# pipe_1 = [(Tokenizer, ), (Lemmatizer,), (concat, None), (tfidf_, tfidf_conf_2),\n",
    "#           (LSVC,), (GetResultLinear_W,)]\n",
    "# pipeline_2 = Pipeline(pipe_1, mode='train', output=None)\n",
    "# pipeline_3 = Pipeline(pipe_1, mode='infer', output='dataset')\n",
    "\n",
    "# res = pipeline_3.run(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run pipeline with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = init_dataset()\n",
    "\n",
    "# conf_0['name'] = 'RandomForestClassifier'\n",
    "# conf_0['op_type'] = 'model'\n",
    "# RFC = skmodel(RandomForestClassifier, conf_0)\n",
    "\n",
    "\n",
    "# # (Speller, spl_conf), \n",
    "# pipe_2 = [(Tokenizer, ), (Lemmatizer,), (concat, None), (tfidf_, tfidf_conf_2),\n",
    "#           (RFC,), (GetResultLinear_W,)]\n",
    "# pipeline_4 = Pipeline(pipe_2, mode='train', output=None)\n",
    "# pipeline_5 = Pipeline(pipe_2, mode='infer', output='dataset')\n",
    "\n",
    "# res = pipeline_5.run(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline with GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from os.path import join\n",
    "\n",
    "# date = datetime.datetime.now()\n",
    "# dataset_name = 'vkusvill'\n",
    "# language = 'russian'\n",
    "# file_path = join('./data', language, dataset_name, 'data', 'vkusvill_all_categories.csv')\n",
    "\n",
    "# dataset = init_dataset_tiny(file_path, language, dataset_name, date)\n",
    "\n",
    "# conf_0['name'] = 'LGBMClassifier'\n",
    "# conf_0['op_type'] = 'model'\n",
    "# LGBM = skmodel(LGBMClassifier, conf_0)\n",
    "\n",
    "# # (Speller, spl_conf),\n",
    "# pipe_3 = [(Tokenizer, ), (Lemmatizer,), (concat, None), (tfidf_, ),\n",
    "#           (LGBM,), (GetResultLinear_W,)]\n",
    "# pipeline_6 = Pipeline(pipe_3, mode='train', output=None)\n",
    "# pipeline_7 = Pipeline(pipe_3, mode='infer', output='dataset')\n",
    "\n",
    "# res = pipeline_7.run(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
