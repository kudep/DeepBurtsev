{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import pymorphy2\n",
    "from os.path import join\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Загрузка; преобразование; чистка;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliable datasets: ['vkusvill']\n",
      "Avaliable files in dataset vkusvill: \n",
      "['07.xls', '17.xls', '03.xls', '11.xls', '15.xls', 'X_test.csv', '08.xls', 'Тип жалобы.xlsx', '04.xls', 'X_train.csv', '12.xls', '14.xls', '10.xls', '02.xls', '01.xls', 'vkusvill_all_categories.csv', '05.xls', 'data_exploration_report.html', '09.xls']\n"
     ]
    }
   ],
   "source": [
    "# загрузка csv файла из датасета\n",
    "dataset_dir = './data/'\n",
    "dataset_names = os.listdir(dataset_dir)\n",
    "print('Avaliable datasets: {}'.format(dataset_names))\n",
    "\n",
    "files = os.listdir(join(dataset_dir, dataset_names[0]))\n",
    "print('Avaliable files in dataset {0}: \\n{1}'.format(dataset_names[0], files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(filepath, duplicates=False, clean=True):\n",
    "    \n",
    "    file = open(filepath, 'r', encoding='ISO-8859-1')\n",
    "    data = pd.read_csv(file)\n",
    "    \n",
    "    old_names = data.keys()\n",
    "    names = [n.encode('ISO-8859-1').decode('cp1251').encode('utf8') for n in old_names]\n",
    "    names = [n.decode('utf-8') for n in names]\n",
    "    \n",
    "    new_data = dict()\n",
    "    for old, new in zip(old_names, names):\n",
    "        new_data[new] = list()\n",
    "        for c in data[old]:\n",
    "            try:\n",
    "                s = c.encode('ISO-8859-1').decode('cp1251').encode('utf8')\n",
    "                s = s.decode('utf-8')\n",
    "                new_data[new].append(s)\n",
    "            except AttributeError:\n",
    "                new_data[new].append(c)\n",
    "    \n",
    "    new_data = pd.DataFrame(new_data, columns=['Описание', 'Категория жалобы'])\n",
    "    new_data.rename(columns={'Описание': 'req', 'Категория жалобы': 'cat'}, inplace=True)\n",
    "    new_data = new_data.dropna()  # dell nan\n",
    "    if not duplicates:\n",
    "        new_data = new_data.drop_duplicates()  # dell duplicates\n",
    "    \n",
    "    # как отдельную ветвь можно использовать\n",
    "    if clean:\n",
    "        delete_bad_symbols = lambda x: \" \".join(re.sub('[^а-яa-zё0-9]', ' ', x.lower()).split())\n",
    "        new_data['req'] = new_data['req'].apply(delete_bad_symbols)\n",
    "    \n",
    "    new_data = new_data.reset_index()\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "def read_dataset_fromV(filepath, duplicates=False, clean=True):\n",
    "    file = open(filepath, 'r')\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "    new_data = pd.DataFrame(data, columns=['Описание', 'Категория жалобы'])\n",
    "    new_data.rename(columns={'Описание': 'req', 'Категория жалобы': 'cat'}, inplace=True)\n",
    "    new_data = new_data.dropna()  # dell nan\n",
    "    if not duplicates:\n",
    "        new_data = new_data.drop_duplicates()  # dell duplicates\n",
    "\n",
    "    # как отдельную ветвь можно использовать\n",
    "    if clean:\n",
    "        delete_bad_symbols = lambda x: \" \".join(re.sub('[^а-яa-zё0-9]', ' ', x.lower()).split())\n",
    "        new_data['req'] = new_data['req'].apply(delete_bad_symbols)\n",
    "\n",
    "    new_data = new_data.reset_index()\n",
    "\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mks/intent/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (6,7,8,9,10,11,13,14,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'req', 'cat'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "path = join(dataset_dir, dataset_names[0], 'X_train.csv')\n",
    "# data = read_dataset(path, False)\n",
    "# data = pd.read_csv(path)\n",
    "data = read_dataset_fromV(path, False)\n",
    "print(data.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         0\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "5         0\n",
      "6         0\n",
      "7         0\n",
      "8         0\n",
      "9         0\n",
      "10        0\n",
      "11        0\n",
      "12        0\n",
      "13        0\n",
      "14        0\n",
      "15        0\n",
      "16        0\n",
      "17        0\n",
      "18        0\n",
      "19        0\n",
      "20        0\n",
      "21        0\n",
      "22        0\n",
      "23        0\n",
      "24        0\n",
      "25        0\n",
      "26        0\n",
      "27        0\n",
      "28        0\n",
      "29        0\n",
      "         ..\n",
      "29665    15\n",
      "29666    16\n",
      "29667    16\n",
      "29668    16\n",
      "29669    16\n",
      "29670    16\n",
      "29671    16\n",
      "29672    16\n",
      "29673    16\n",
      "29674    16\n",
      "29675    16\n",
      "29676    16\n",
      "29677    16\n",
      "29678    16\n",
      "29679    16\n",
      "29680    16\n",
      "29681    16\n",
      "29682    16\n",
      "29683    16\n",
      "29684    16\n",
      "29685    16\n",
      "29686    16\n",
      "29687    16\n",
      "29688    16\n",
      "29689    16\n",
      "29690    16\n",
      "29691    16\n",
      "29692    16\n",
      "29693    16\n",
      "29694    16\n",
      "Name: cat, Length: 29695, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data['cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "index = []\n",
    "for i in range(len(data['cat'])):\n",
    "    try:\n",
    "        v = data['cat'][i]\n",
    "    except KeyError:\n",
    "        index.append(i)\n",
    "        k += 1\n",
    "\n",
    "print(k)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Датасет теперь не содержит пропущенных значений, пустых строк, или запросов без указания к какому класса они относятся. Однако есть повторяющиеся значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "активация мтс            20\n",
       "активация                14\n",
       "вопросы по лп             9\n",
       "лп                        9\n",
       "привязали чек к карте     7\n",
       "Name: req, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['req'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Повторяются чаще всего короткие обращения всего в несколько слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего запросов: 58780\n",
      "Количество запросов после сортировки: 44652\n",
      "Количество повторяющихся запросов: 14128\n"
     ]
    }
   ],
   "source": [
    "print('Всего запросов: {}'.format(len(data['req'])))\n",
    "print('Количество запросов после сортировки: {}'.format(len(data['req'].unique())))\n",
    "print('Количество повторяющихся запросов: {}'.format(len(data['req']) - len(data['req'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mks/intent/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2850: DtypeWarning: Columns (6,7,10,14) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['req', 'cat'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "активация мтс            20\n",
       "активация                14\n",
       "вопросы по лп             9\n",
       "лп                        9\n",
       "привязали чек к карте     7\n",
       "Name: req, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = join(dataset_dir, dataset_names[0], 'vkusvill_all_categories.csv')\n",
    "data = read_dataset(path)\n",
    "print(data.keys())\n",
    "\n",
    "data['req'].value_counts().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Препроцессинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование классов. Создание класса \"Others\" и перенос в него соответствующих данных по значению порога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_(data):\n",
    "    \n",
    "    clas = data['Категория жалобы'].unique()\n",
    "    cld = dict()\n",
    "    cll = list()\n",
    "    \n",
    "    for x in clas:\n",
    "        cld[x] = data[data['Категория жалобы'] == x]['Категория жалобы'].value_counts()\n",
    "        cll.append(data[data['Категория жалобы'] == x]['Категория жалобы'].value_counts())\n",
    "    \n",
    "    cll = np.array(cll)\n",
    "    mean = cll.mean()\n",
    "    \n",
    "    new_cl = 0\n",
    "    k = 1\n",
    "    for i, x in enumerate(clas):\n",
    "        if cld[x] <= 0.5*mean:  # rule for \"others\" class\n",
    "            new_cl += cld[x]\n",
    "            cld[x] = 0\n",
    "        else:\n",
    "            cld[x] = k + 1\n",
    "    \n",
    "    for x in clas:\n",
    "        data[data['Категория жалобы'] == x]['Категория жалобы'] = cld[x]\n",
    "    \n",
    "    print('Request in others: {}'.format(new_cl))\n",
    "    return data\n",
    "\n",
    "\n",
    "def other(data, threshold='half_mean'):\n",
    "    \n",
    "    clas = data['Категория жалобы'].unique()\n",
    "    cld = dict()\n",
    "    cll = list()\n",
    "    \n",
    "    for x in clas:\n",
    "        d = data[data['Категория жалобы'] == x]['Категория жалобы'].value_counts()\n",
    "        c = int(list(d.items())[0][1])\n",
    "        cld[x] = c\n",
    "        cll.append(c)\n",
    "    \n",
    "    cll = np.array(cll)\n",
    "    mean = cll.mean()\n",
    "    print(mean)\n",
    "    \n",
    "    new_cl = 0\n",
    "    k = 1\n",
    "    for i, x in enumerate(clas):\n",
    "        if cld[x] <= 0.5*mean:  # rule for \"others\" class\n",
    "            new_cl += cld[x]\n",
    "            cld[x] = 0\n",
    "        else:\n",
    "            cld[x] = k + 1\n",
    "    \n",
    "    for x in clas:\n",
    "        data['Категория жалобы'] = cld[x]\n",
    "    \n",
    "    print('Request in others: {}'.format(new_cl))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** 0 17 ***\n",
      "1                                                  3288\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 1 1 ***\n",
      "2                                                  5312\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 2 2 ***\n",
      "3                                                  6791\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 3 3 ***\n",
      "4                                                  1366\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 4 4 ***\n",
      "5                                                  80\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 5 5 ***\n",
      "6                                                  9600\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 6 6 ***\n",
      "7                                                  3634\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 7 7 ***\n",
      "8                                                  442\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 8 8 ***\n",
      "9                                                  906\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 9 9 ***\n",
      "10                                                 3501\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 10 10 ***\n",
      "11                                                 2039\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 11 11 ***\n",
      "12                                                 2287\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 12 12 ***\n",
      "13                                                 3568\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 13 13 ***\n",
      "14                                                 205\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 14 14 ***\n",
      "15                                                 1188\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 15 15 ***\n",
      "16                                                 922\n",
      "----------------------------------------------------------------------------------------------------\n",
      "*** 16 16 ***\n",
      "17                                                 42\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "classes = data['cat'].unique()\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    s = data[data['cat'] == classes[i]]['cat'].value_counts()\n",
    "    print('*** {} {} ***'.format(i, classes[i - 1]))\n",
    "    print('\\n'.join(['{:<50} {}'.format(x[0], x[1]) for x in list(s.items())]))\n",
    "    print('-' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2657.1176470588234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mks/intent/lib/python3.6/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request in others: 3785\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17]\n"
     ]
    }
   ],
   "source": [
    "data_ = other(data)\n",
    "\n",
    "print(data_['cat'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "день добрый всегда был доволен качеством ваших продуктов берем всей семьей и друзьями рекомендовали 13 08 2016 в магазине вкусвил на бульваре яна райниса д 2 корп 1 закупился продуктами карты 1713654 в числе которых был творог 9 сегодня открыл и попробовал его и поранился осколками стекла которые были в нем кусок стекла который вытащил могу при необходимости сфотографировать и отправить не знаю что еще написать с уважением антон близнюк skype antonith моб 89060482086 сегодня вернулся с работы и обнаружил что мои выбросили упаковку просто возьмите на заметку\n",
      "['день', 'добрый', 'всегда', 'был', 'доволен', 'качеством', 'ваших', 'продуктов', 'берем', 'всей', 'семьей', 'и', 'друзьями', 'рекомендовали', '13', '08', '2016', 'в', 'магазине', 'вкусвил', 'на', 'бульваре', 'яна', 'райниса', 'д', '2', 'корп', '1', 'закупился', 'продуктами', 'карты', '1713654', 'в', 'числе', 'которых', 'был', 'творог', '9', 'сегодня', 'открыл', 'и', 'попробовал', 'его', 'и', 'поранился', 'осколками', 'стекла', 'которые', 'были', 'в', 'нем', 'кусок', 'стекла', 'который', 'вытащил', 'могу', 'при', 'необходимости', 'сфотографировать', 'и', 'отправить', 'не', 'знаю', 'что', 'еще', 'написать', 'с', 'уважением', 'антон', 'близнюк', 'skype', 'antonith', 'моб', '89060482086', 'сегодня', 'вернулся', 'с', 'работы', 'и', 'обнаружил', 'что', 'мои', 'выбросили', 'упаковку', 'просто', 'возьмите', 'на', 'заметку']\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('punkt')\n",
    "sent = data['req'][5]\n",
    "tags = nltk.word_tokenize(sent)\n",
    "print(sent)\n",
    "print(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "день добрый всегда был доволен качеством ваших продуктов берем всей семьей и друзьями рекомендовали 13 08 2016 в магазине вкусвил на бульваре яна райниса д 2 корп 1 закупился продуктами карты 1713654 в числе которых был творог 9 сегодня открыл и попробовал его и поранился осколками стекла которые были в нем кусок стекла который вытащил могу при необходимости сфотографировать и отправить не знаю что еще написать с уважением антон близнюк skype antonith моб 89060482086 сегодня вернулся с работы и обнаружил что мои выбросили упаковку просто возьмите на заметку\n",
      "['день добрый всегда был доволен качеством ваших продуктов берем всей семьей и друзьями рекомендовали 13 08 2016 в магазине вкусвил на бульваре яна райниса д 2 корп 1 закупился продуктами карты 1713654 в числе которых был творог 9 сегодня открыл и попробовал его и поранился осколками стекла которые были в нем кусок стекла который вытащил могу при необходимости сфотографировать и отправить не знаю что еще написать с уважением антон близнюк skype antonith моб 89060482086 сегодня вернулся с работы и обнаружил что мои выбросили упаковку просто возьмите на заметку']\n",
      "['день', 'добрый', 'всегда', 'был', 'доволен', 'качеством', 'ваших', 'продуктов', 'берем', 'всей', 'семьей', 'и', 'друзьями', 'рекомендовали', '13', '08', '2016', 'в', 'магазине', 'вкусвил', 'на', 'бульваре', 'яна', 'райниса', 'д', '2', 'корп', '1', 'закупился', 'продуктами', 'карты', '1713654', 'в', 'числе', 'которых', 'был', 'творог', '9', 'сегодня', 'открыл', 'и', 'попробовал', 'его', 'и', 'поранился', 'осколками', 'стекла', 'которые', 'были', 'в', 'нем', 'кусок', 'стекла', 'который', 'вытащил', 'могу', 'при', 'необходимости', 'сфотографировать', 'и', 'отправить', 'не', 'знаю', 'что', 'еще', 'написать', 'с', 'уважением', 'антон', 'близнюк', 'skype', 'antonith', 'моб', '89060482086', 'сегодня', 'вернулся', 'с', 'работы', 'и', 'обнаружил', 'что', 'мои', 'выбросили', 'упаковку', 'просто', 'возьмите', 'на', 'заметку']\n"
     ]
    }
   ],
   "source": [
    "sent = data['req'][5]\n",
    "sentences = nltk.sent_tokenize(sent)\n",
    "\n",
    "print(sent)\n",
    "print(sentences)\n",
    "\n",
    "for s in sentences:\n",
    "    tags = nltk.word_tokenize(s)\n",
    "    print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "def tokenize(sen):\n",
    "    sent_toks = nltk.sent_tokenize(sen)\n",
    "    word_toks = [nltk.word_tokenize(el) for el in sent_toks]\n",
    "    tokens = [val for sublist in word_toks for val in sublist]\n",
    "    tokens = [el for el in tokens if el != '']\n",
    "    tokens = [el.lower() for el in tokens]\n",
    "    tokens = [morph.parse(el)[0].normal_form for el in tokens]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokens = tokenize(data['req'][5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasttext import load_model\n",
    "emb_dict = load_model('./embeddings/russian/ft_0.8.3_nltk_yalen_sg_300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ну что жe.', 'Настало время проверить всё ли нормально.']\n",
      "['Настало', 'время', 'проверить', 'всё', 'ли', 'нормально', '.']\n",
      "['ну', 'что', 'жe', '.', 'настать', 'время', 'проверить', 'весь', 'ли', 'нормальный', '.']\n"
     ]
    }
   ],
   "source": [
    "emb = np.zeros((len(Tokens), 300))\n",
    "for i, x in enumerate(Tokens):\n",
    "    emb[i] = emb_dict[x]\n",
    "\n",
    "print(emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ну что жe.', 'Настало время проверить всё ли нормально.']\n",
      "['Настало', 'время', 'проверить', 'всё', 'ли', 'нормально', '.']\n",
      "['ну', 'что', 'жe', '.', 'настать', 'время', 'проверить', 'весь', 'ли', 'нормальный', '.']\n"
     ]
    }
   ],
   "source": [
    "s = 'Ну что жe. Настало время проверить всё ли нормально.'\n",
    "sent = nltk.sent_tokenize(s)\n",
    "print(sent)\n",
    "for x in sent:\n",
    "    tok = nltk.word_tokenize(x)\n",
    "print(tok)\n",
    "\n",
    "tok_ = tokenize(s)\n",
    "print(tok_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-25e67f2625f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def tokenization(data, morph=True):\n",
    "    dataset = list()\n",
    "    ans = list()\n",
    "    \n",
    "    for x, y in tqdm(zip(data['req'], data['cat'])):\n",
    "        if morph:\n",
    "            tokens = tokenize(x)\n",
    "        else:\n",
    "            sent = nltk.sent_tokenize(x)\n",
    "            word_toks = [nltk.word_tokenize(el) for el in sent]\n",
    "            tokens = [val for sublist in word_toks for val in sublist]\n",
    "        \n",
    "        dataset.append(tokens)\n",
    "        ans.append(y)    \n",
    "    \n",
    "    return dataset, ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-25e67f2625f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "x, y = tokenization(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-25e67f2625f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print(x[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-25e67f2625f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# разбиваем датасет на train/test с сохранением соотношений\n",
    "n = 2\n",
    "skf = StratifiedShuffleSplit(n_splits=n, test_size=0.2, random_state=0)\n",
    "# skf.get_n_splits(x, y)\n",
    "\n",
    "dataset = list()\n",
    "for train_index, test_index in skf.split(x, y):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    Y_train, Y_test = y[train_index], y[test_index]\n",
    "    dataset.append(((X_train, Y_train), (X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "X, Y = make_classification(n_features=4, random_state=0)\n",
    "clf = LinearSVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 massive:\n",
      " [0.84705882 0.77419355 0.693      0.13793103 0.001      0.85813953\n",
      " 0.76339869 0.28732394 0.525      0.76470588 0.634375   0.64310078\n",
      " 0.75       0.03920792 0.84423529 0.84705882]\n",
      "F1 macro: 0.5881080796088309\n"
     ]
    }
   ],
   "source": [
    "prec = [0.9, 0.75, 0.63, 0.5, 0.001, 0.82, 0.73, 0.51, 0.7, 0.75, 0.7, 0.68, 0.75, 0.99, 0.92, 0.8]\n",
    "recall = [0.8, 0.8, 0.77, 0.08, 0.001, 0.9, 0.8, 0.2, 0.42, 0.78, 0.58, 0.61, 0.75, 0.02, 0.78, 0.9]\n",
    "\n",
    "prec = np.array(prec)\n",
    "rec = np.array(recall)\n",
    "\n",
    "f1_ = 2 * (prec * rec)/(prec + rec)\n",
    "print('F1 massive:\\n {}'.format(f1_))\n",
    "\n",
    "f1 = np.mean(f1_)\n",
    "print('F1 macro: {}'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_dict = dict()\n",
    "\n",
    "for x in data['cat'].unique():\n",
    "    scoring_dict[x] = list()\n",
    "    \n",
    "for i in range(len(data)):\n",
    "    scoring_dict[data['cat'][i]].append((data['req'][i], data['cat'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3288\n"
     ]
    }
   ],
   "source": [
    "print(len(scoring_dict[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5.]\n",
      " [5. 5. 5. 5. 5.]]\n"
     ]
    }
   ],
   "source": [
    "z = np.zeros((5, 5))\n",
    "n = np.ones_like(z) * 5\n",
    "print(z)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
